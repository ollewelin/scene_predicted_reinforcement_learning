************************************************************************************************
Normal mode is selected by user Next scene network will be used with frame future f-2,f-1,f0,f+1 
skip_scene_predictor_only_for_benchmarking = 0
************************************************************************************************
Parmeters settings :
next_scene_hid_nodes_L1 = 200
next_scene_hid_nodes_L2 = 200
next_scene_hid_nodes_L3 = 200
policy_net_hid_nodes_L1 = 85
policy_net_hid_nodes_L2 = 25
policy_net_hid_nodes_L3 = 10
next_scene_fc_net.learning_rate = 0.001
next_scene_fc_net.momentum = 0.1
policy_fc_net.learning_rate = 0.001
policy_fc_net.momentum = 0.2
g_replay_size = 200
derating_epsilon = 0.0005
gamma_decay = 0.85
target_policy_on_next_action_selection = 1
target_policy_use_f_p_2_pixel_from_predict_net = 1
target_off_set_to_output_itself = 1
skip_traning_next_scenen = 0
policy_fc_net.use_dropouts =0
policy_fc_net.dropout_proportion = 0
retrain_policy_net = 1
epoch = 1 epsilon = 0.2495 retrain_policy net = 0 Policy net Loss = 1726.46
epoch = 2 epsilon = 0.249 retrain_policy net = 0 Policy net Loss = 1645.46
epoch = 3 epsilon = 0.2485 retrain_policy net = 0 Policy net Loss = 1727.4
epoch = 4 epsilon = 0.248 retrain_policy net = 0 Policy net Loss = 1620.77
epoch = 5 epsilon = 0.2475 retrain_policy net = 0 Policy net Loss = 1692.3
epoch = 6 epsilon = 0.247 retrain_policy net = 0 Policy net Loss = 1666.99
epoch = 7 epsilon = 0.2465 retrain_policy net = 0 Policy net Loss = 1655.49
epoch = 8 epsilon = 0.246 retrain_policy net = 0 Policy net Loss = 1679.22
epoch = 9 epsilon = 0.2455 retrain_policy net = 0 Policy net Loss = 1664.23
epoch = 10 epsilon = 0.245 retrain_policy net = 0 Policy net Loss = 1662.06
epoch = 11 epsilon = 0.2445 retrain_policy net = 0 Policy net Loss = 1678.96
epoch = 12 epsilon = 0.244 retrain_policy net = 0 Policy net Loss = 1608.47
epoch = 13 epsilon = 0.2435 retrain_policy net = 0 Policy net Loss = 1598.08
epoch = 14 epsilon = 0.243 retrain_policy net = 0 Policy net Loss = 1655.78
epoch = 15 epsilon = 0.2425 retrain_policy net = 0 Policy net Loss = 1687.06
epoch = 16 epsilon = 0.242 retrain_policy net = 0 Policy net Loss = 1631.64
epoch = 17 epsilon = 0.2415 retrain_policy net = 0 Policy net Loss = 1545.92
epoch = 18 epsilon = 0.241 retrain_policy net = 0 Policy net Loss = 1701.73
epoch = 19 epsilon = 0.2405 retrain_policy net = 0 Policy net Loss = 1569.42
epoch = 20 epsilon = 0.24 retrain_policy net = 0 Policy net Loss = 1514.38
epoch = 21 epsilon = 0.2395 retrain_policy net = 0 Policy net Loss = 1558.41
epoch = 22 epsilon = 0.239 retrain_policy net = 0 Policy net Loss = 1596.78
epoch = 23 epsilon = 0.2385 retrain_policy net = 0 Policy net Loss = 1715.12
epoch = 24 epsilon = 0.238 retrain_policy net = 0 Policy net Loss = 1702.34
epoch = 25 epsilon = 0.2375 retrain_policy net = 0 Policy net Loss = 1629.62
epoch = 26 epsilon = 0.237 retrain_policy net = 0 Policy net Loss = 1648.59
epoch = 27 epsilon = 0.2365 retrain_policy net = 0 Policy net Loss = 1578.57
epoch = 28 epsilon = 0.236 retrain_policy net = 0 Policy net Loss = 1709.67
epoch = 29 epsilon = 0.2355 retrain_policy net = 0 Policy net Loss = 1655.07
epoch = 30 epsilon = 0.235 retrain_policy net = 0 Policy net Loss = 1683.18
epoch = 31 epsilon = 0.2345 retrain_policy net = 0 Policy net Loss = 1608.57
epoch = 32 epsilon = 0.234 retrain_policy net = 0 Policy net Loss = 1644.26
epoch = 33 epsilon = 0.2335 retrain_policy net = 0 Policy net Loss = 1805.8
epoch = 34 epsilon = 0.233 retrain_policy net = 0 Policy net Loss = 1687.7
epoch = 35 epsilon = 0.2325 retrain_policy net = 0 Policy net Loss = 1681.15
epoch = 36 epsilon = 0.232 retrain_policy net = 0 Policy net Loss = 1668.8
epoch = 37 epsilon = 0.2315 retrain_policy net = 0 Policy net Loss = 1563.41
epoch = 38 epsilon = 0.231 retrain_policy net = 0 Policy net Loss = 1768.64
epoch = 39 epsilon = 0.2305 retrain_policy net = 0 Policy net Loss = 1735.43
epoch = 40 epsilon = 0.23 retrain_policy net = 0 Policy net Loss = 1726.13
epoch = 41 epsilon = 0.2295 retrain_policy net = 0 Policy net Loss = 1587.84
epoch = 42 epsilon = 0.229 retrain_policy net = 0 Policy net Loss = 1713.05
epoch = 43 epsilon = 0.2285 retrain_policy net = 0 Policy net Loss = 1664.36
