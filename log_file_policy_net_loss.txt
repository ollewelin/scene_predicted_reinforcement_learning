************************************************************************************************
Normal mode is selected by user Next scene network will be used with frame future f-2,f-1,f0,f+1 
skip_scene_predictor_only_for_benchmarking = 0
************************************************************************************************
Parmeters settings :
next_scene_hid_nodes_L1 = 200
next_scene_hid_nodes_L2 = 200
next_scene_hid_nodes_L3 = 200
policy_net_hid_nodes_L1 = 85
policy_net_hid_nodes_L2 = 25
policy_net_hid_nodes_L3 = 10
next_scene_fc_net.learning_rate = 0.001
next_scene_fc_net.momentum = 0.1
policy_fc_net.learning_rate = 0.001
policy_fc_net.momentum = 0.2
g_replay_size = 200
derating_epsilon = 0.0005
gamma_decay = 0.85
target_policy_on_next_action_selection = 1
target_policy_use_f_p_2_pixel_from_predict_net = 1
target_off_set_to_output_itself = 1
skip_traning_next_scenen = 0
policy_fc_net.use_dropouts =0
policy_fc_net.dropout_proportion = 0
retrain_policy_net = 1
epoch = 1 epsilon = 0.2495 retrain_policy net = 0 Policy net Loss = 1726.46
epoch = 2 epsilon = 0.249 retrain_policy net = 0 Policy net Loss = 1645.46
epoch = 3 epsilon = 0.2485 retrain_policy net = 0 Policy net Loss = 1727.4
epoch = 4 epsilon = 0.248 retrain_policy net = 0 Policy net Loss = 1620.77
epoch = 5 epsilon = 0.2475 retrain_policy net = 0 Policy net Loss = 1692.3
epoch = 6 epsilon = 0.247 retrain_policy net = 0 Policy net Loss = 1666.99
epoch = 7 epsilon = 0.2465 retrain_policy net = 0 Policy net Loss = 1655.49
epoch = 8 epsilon = 0.246 retrain_policy net = 0 Policy net Loss = 1679.22
epoch = 9 epsilon = 0.2455 retrain_policy net = 0 Policy net Loss = 1664.23
epoch = 10 epsilon = 0.245 retrain_policy net = 0 Policy net Loss = 1662.06
epoch = 11 epsilon = 0.2445 retrain_policy net = 0 Policy net Loss = 1678.96
epoch = 12 epsilon = 0.244 retrain_policy net = 0 Policy net Loss = 1608.47
epoch = 13 epsilon = 0.2435 retrain_policy net = 0 Policy net Loss = 1598.08
epoch = 14 epsilon = 0.243 retrain_policy net = 0 Policy net Loss = 1655.78
epoch = 15 epsilon = 0.2425 retrain_policy net = 0 Policy net Loss = 1687.06
epoch = 16 epsilon = 0.242 retrain_policy net = 0 Policy net Loss = 1631.64
epoch = 17 epsilon = 0.2415 retrain_policy net = 0 Policy net Loss = 1545.92
epoch = 18 epsilon = 0.241 retrain_policy net = 0 Policy net Loss = 1701.73
epoch = 19 epsilon = 0.2405 retrain_policy net = 0 Policy net Loss = 1569.42
epoch = 20 epsilon = 0.24 retrain_policy net = 0 Policy net Loss = 1514.38
epoch = 21 epsilon = 0.2395 retrain_policy net = 0 Policy net Loss = 1558.41
epoch = 22 epsilon = 0.239 retrain_policy net = 0 Policy net Loss = 1596.78
epoch = 23 epsilon = 0.2385 retrain_policy net = 0 Policy net Loss = 1715.12
epoch = 24 epsilon = 0.238 retrain_policy net = 0 Policy net Loss = 1702.34
epoch = 25 epsilon = 0.2375 retrain_policy net = 0 Policy net Loss = 1629.62
epoch = 26 epsilon = 0.237 retrain_policy net = 0 Policy net Loss = 1648.59
epoch = 27 epsilon = 0.2365 retrain_policy net = 0 Policy net Loss = 1578.57
epoch = 28 epsilon = 0.236 retrain_policy net = 0 Policy net Loss = 1709.67
epoch = 29 epsilon = 0.2355 retrain_policy net = 0 Policy net Loss = 1655.07
epoch = 30 epsilon = 0.235 retrain_policy net = 0 Policy net Loss = 1683.18
epoch = 31 epsilon = 0.2345 retrain_policy net = 0 Policy net Loss = 1608.57
epoch = 32 epsilon = 0.234 retrain_policy net = 0 Policy net Loss = 1644.26
epoch = 33 epsilon = 0.2335 retrain_policy net = 0 Policy net Loss = 1805.8
epoch = 34 epsilon = 0.233 retrain_policy net = 0 Policy net Loss = 1687.7
epoch = 35 epsilon = 0.2325 retrain_policy net = 0 Policy net Loss = 1681.15
epoch = 36 epsilon = 0.232 retrain_policy net = 0 Policy net Loss = 1668.8
epoch = 37 epsilon = 0.2315 retrain_policy net = 0 Policy net Loss = 1563.41
epoch = 38 epsilon = 0.231 retrain_policy net = 0 Policy net Loss = 1768.64
epoch = 39 epsilon = 0.2305 retrain_policy net = 0 Policy net Loss = 1735.43
epoch = 40 epsilon = 0.23 retrain_policy net = 0 Policy net Loss = 1726.13
epoch = 41 epsilon = 0.2295 retrain_policy net = 0 Policy net Loss = 1587.84
epoch = 42 epsilon = 0.229 retrain_policy net = 0 Policy net Loss = 1713.05
epoch = 43 epsilon = 0.2285 retrain_policy net = 0 Policy net Loss = 1664.36
epoch = 44 epsilon = 0.228 retrain_policy net = 0 Policy net Loss = 1618.88
epoch = 45 epsilon = 0.2275 retrain_policy net = 0 Policy net Loss = 1610.41
epoch = 46 epsilon = 0.227 retrain_policy net = 0 Policy net Loss = 1941.04
epoch = 47 epsilon = 0.2265 retrain_policy net = 0 Policy net Loss = 1754.42
epoch = 48 epsilon = 0.226 retrain_policy net = 0 Policy net Loss = 1573.63
epoch = 49 epsilon = 0.2255 retrain_policy net = 0 Policy net Loss = 1621.57
epoch = 50 epsilon = 0.225 retrain_policy net = 0 Policy net Loss = 1642.13
epoch = 51 epsilon = 0.2245 retrain_policy net = 0 Policy net Loss = 1605.88
epoch = 52 epsilon = 0.224 retrain_policy net = 0 Policy net Loss = 1698.31
epoch = 53 epsilon = 0.2235 retrain_policy net = 0 Policy net Loss = 1830.36
epoch = 54 epsilon = 0.223 retrain_policy net = 0 Policy net Loss = 1740.3
epoch = 55 epsilon = 0.2225 retrain_policy net = 0 Policy net Loss = 1604.01
epoch = 56 epsilon = 0.222 retrain_policy net = 0 Policy net Loss = 1625.08
epoch = 57 epsilon = 0.2215 retrain_policy net = 0 Policy net Loss = 1799.28
epoch = 58 epsilon = 0.221 retrain_policy net = 0 Policy net Loss = 1663.81
epoch = 59 epsilon = 0.2205 retrain_policy net = 0 Policy net Loss = 1543.22
epoch = 60 epsilon = 0.22 retrain_policy net = 0 Policy net Loss = 1675.27
epoch = 61 epsilon = 0.2195 retrain_policy net = 0 Policy net Loss = 1689.95
epoch = 62 epsilon = 0.219 retrain_policy net = 0 Policy net Loss = 1600.67
epoch = 63 epsilon = 0.2185 retrain_policy net = 0 Policy net Loss = 1661.22
epoch = 64 epsilon = 0.218 retrain_policy net = 0 Policy net Loss = 1599.21
epoch = 65 epsilon = 0.2175 retrain_policy net = 0 Policy net Loss = 1880.91
epoch = 66 epsilon = 0.217 retrain_policy net = 0 Policy net Loss = 1646.18
epoch = 67 epsilon = 0.2165 retrain_policy net = 0 Policy net Loss = 1777.69
epoch = 68 epsilon = 0.216 retrain_policy net = 0 Policy net Loss = 1637.5
epoch = 69 epsilon = 0.2155 retrain_policy net = 0 Policy net Loss = 1575.6
epoch = 70 epsilon = 0.215 retrain_policy net = 0 Policy net Loss = 1478.76
epoch = 71 epsilon = 0.2145 retrain_policy net = 0 Policy net Loss = 1634.81
epoch = 72 epsilon = 0.214 retrain_policy net = 0 Policy net Loss = 1608.41
epoch = 73 epsilon = 0.2135 retrain_policy net = 0 Policy net Loss = 1599.57
epoch = 74 epsilon = 0.213 retrain_policy net = 0 Policy net Loss = 1607.97
epoch = 75 epsilon = 0.2125 retrain_policy net = 0 Policy net Loss = 1691.25
epoch = 76 epsilon = 0.212 retrain_policy net = 0 Policy net Loss = 1674.03
epoch = 77 epsilon = 0.2115 retrain_policy net = 0 Policy net Loss = 1744.28
epoch = 78 epsilon = 0.211 retrain_policy net = 0 Policy net Loss = 1582.35
epoch = 79 epsilon = 0.2105 retrain_policy net = 0 Policy net Loss = 1561.32
epoch = 80 epsilon = 0.21 retrain_policy net = 0 Policy net Loss = 1592.61
epoch = 81 epsilon = 0.2095 retrain_policy net = 0 Policy net Loss = 1430.82
epoch = 82 epsilon = 0.209 retrain_policy net = 0 Policy net Loss = 1500.05
epoch = 83 epsilon = 0.2085 retrain_policy net = 0 Policy net Loss = 1666.01
epoch = 84 epsilon = 0.208 retrain_policy net = 0 Policy net Loss = 1500.89
epoch = 85 epsilon = 0.2075 retrain_policy net = 0 Policy net Loss = 1526.56
epoch = 86 epsilon = 0.207 retrain_policy net = 0 Policy net Loss = 1642.26
epoch = 87 epsilon = 0.2065 retrain_policy net = 0 Policy net Loss = 1586.92
epoch = 88 epsilon = 0.206 retrain_policy net = 0 Policy net Loss = 1649.67
epoch = 89 epsilon = 0.2055 retrain_policy net = 0 Policy net Loss = 1515.58
epoch = 90 epsilon = 0.205 retrain_policy net = 0 Policy net Loss = 1511.18
epoch = 91 epsilon = 0.2045 retrain_policy net = 0 Policy net Loss = 1418.7
epoch = 92 epsilon = 0.204 retrain_policy net = 0 Policy net Loss = 1638.76
epoch = 93 epsilon = 0.2035 retrain_policy net = 0 Policy net Loss = 1662.67
epoch = 94 epsilon = 0.203 retrain_policy net = 0 Policy net Loss = 1714.15
epoch = 95 epsilon = 0.2025 retrain_policy net = 0 Policy net Loss = 1623.57
epoch = 96 epsilon = 0.202 retrain_policy net = 0 Policy net Loss = 1523.85
epoch = 97 epsilon = 0.2015 retrain_policy net = 0 Policy net Loss = 1572.07
epoch = 98 epsilon = 0.201 retrain_policy net = 0 Policy net Loss = 1546.18
epoch = 99 epsilon = 0.2005 retrain_policy net = 0 Policy net Loss = 1661.87
epoch = 100 epsilon = 0.2 retrain_policy net = 0 Policy net Loss = 1550.04
epoch = 101 epsilon = 0.1995 retrain_policy net = 0 Policy net Loss = 1563.68
epoch = 102 epsilon = 0.199 retrain_policy net = 0 Policy net Loss = 1536.25
epoch = 103 epsilon = 0.1985 retrain_policy net = 0 Policy net Loss = 1716.86
epoch = 104 epsilon = 0.198 retrain_policy net = 0 Policy net Loss = 1579.42
epoch = 105 epsilon = 0.1975 retrain_policy net = 0 Policy net Loss = 1589
epoch = 106 epsilon = 0.197 retrain_policy net = 0 Policy net Loss = 1626.57
epoch = 107 epsilon = 0.1965 retrain_policy net = 0 Policy net Loss = 1699.39
epoch = 108 epsilon = 0.196 retrain_policy net = 0 Policy net Loss = 1341.23
epoch = 109 epsilon = 0.1955 retrain_policy net = 0 Policy net Loss = 1673.55
epoch = 110 epsilon = 0.195 retrain_policy net = 0 Policy net Loss = 1673.96
epoch = 111 epsilon = 0.1945 retrain_policy net = 0 Policy net Loss = 1784.28
epoch = 112 epsilon = 0.194 retrain_policy net = 0 Policy net Loss = 1581.88
epoch = 113 epsilon = 0.1935 retrain_policy net = 0 Policy net Loss = 1534.86
epoch = 114 epsilon = 0.193 retrain_policy net = 0 Policy net Loss = 1533.58
epoch = 115 epsilon = 0.1925 retrain_policy net = 0 Policy net Loss = 1587.57
epoch = 116 epsilon = 0.192 retrain_policy net = 0 Policy net Loss = 1480.6
epoch = 117 epsilon = 0.1915 retrain_policy net = 0 Policy net Loss = 1468.75
epoch = 118 epsilon = 0.191 retrain_policy net = 0 Policy net Loss = 1465.68
epoch = 119 epsilon = 0.1905 retrain_policy net = 0 Policy net Loss = 1638.02
epoch = 120 epsilon = 0.19 retrain_policy net = 0 Policy net Loss = 1658.67
epoch = 121 epsilon = 0.1895 retrain_policy net = 0 Policy net Loss = 1504.71
epoch = 122 epsilon = 0.189 retrain_policy net = 0 Policy net Loss = 1534.47
epoch = 123 epsilon = 0.1885 retrain_policy net = 0 Policy net Loss = 1697.74
epoch = 124 epsilon = 0.188 retrain_policy net = 0 Policy net Loss = 1732.85
epoch = 125 epsilon = 0.1875 retrain_policy net = 0 Policy net Loss = 1535.67
epoch = 126 epsilon = 0.187 retrain_policy net = 0 Policy net Loss = 1783.41
epoch = 127 epsilon = 0.1865 retrain_policy net = 0 Policy net Loss = 1532.45
epoch = 128 epsilon = 0.186 retrain_policy net = 0 Policy net Loss = 1738.98
epoch = 129 epsilon = 0.1855 retrain_policy net = 0 Policy net Loss = 1577.01
epoch = 130 epsilon = 0.185 retrain_policy net = 0 Policy net Loss = 1494.76
epoch = 131 epsilon = 0.1845 retrain_policy net = 0 Policy net Loss = 1646.65
epoch = 132 epsilon = 0.184 retrain_policy net = 0 Policy net Loss = 1806.71
epoch = 133 epsilon = 0.1835 retrain_policy net = 0 Policy net Loss = 1604.36
epoch = 134 epsilon = 0.183 retrain_policy net = 0 Policy net Loss = 1624.36
epoch = 135 epsilon = 0.1825 retrain_policy net = 0 Policy net Loss = 1676.94
epoch = 136 epsilon = 0.182 retrain_policy net = 0 Policy net Loss = 1561.74
epoch = 137 epsilon = 0.1815 retrain_policy net = 0 Policy net Loss = 1663.71
epoch = 138 epsilon = 0.181 retrain_policy net = 0 Policy net Loss = 1651.46
epoch = 139 epsilon = 0.1805 retrain_policy net = 0 Policy net Loss = 1555.44
epoch = 140 epsilon = 0.18 retrain_policy net = 0 Policy net Loss = 1511.14
epoch = 141 epsilon = 0.1795 retrain_policy net = 0 Policy net Loss = 1713.41
epoch = 142 epsilon = 0.179 retrain_policy net = 0 Policy net Loss = 1529.97
epoch = 143 epsilon = 0.1785 retrain_policy net = 0 Policy net Loss = 1660.09
epoch = 144 epsilon = 0.178 retrain_policy net = 0 Policy net Loss = 1671.73
epoch = 145 epsilon = 0.1775 retrain_policy net = 0 Policy net Loss = 1492.64
epoch = 146 epsilon = 0.177 retrain_policy net = 0 Policy net Loss = 1550.28
epoch = 147 epsilon = 0.1765 retrain_policy net = 0 Policy net Loss = 1555.17
epoch = 148 epsilon = 0.176 retrain_policy net = 0 Policy net Loss = 1683
epoch = 149 epsilon = 0.1755 retrain_policy net = 0 Policy net Loss = 1637.57
epoch = 150 epsilon = 0.175 retrain_policy net = 0 Policy net Loss = 1982.24
epoch = 151 epsilon = 0.1745 retrain_policy net = 0 Policy net Loss = 1565.25
epoch = 152 epsilon = 0.174 retrain_policy net = 0 Policy net Loss = 1697.23
epoch = 153 epsilon = 0.1735 retrain_policy net = 0 Policy net Loss = 1526.61
epoch = 154 epsilon = 0.173 retrain_policy net = 0 Policy net Loss = 1529.53
epoch = 155 epsilon = 0.1725 retrain_policy net = 0 Policy net Loss = 1677.04
epoch = 156 epsilon = 0.172 retrain_policy net = 0 Policy net Loss = 1610.51
epoch = 157 epsilon = 0.1715 retrain_policy net = 0 Policy net Loss = 1557.33
epoch = 158 epsilon = 0.171 retrain_policy net = 0 Policy net Loss = 1562.58
epoch = 159 epsilon = 0.1705 retrain_policy net = 0 Policy net Loss = 1510.22
epoch = 160 epsilon = 0.17 retrain_policy net = 0 Policy net Loss = 1515.6
epoch = 161 epsilon = 0.1695 retrain_policy net = 0 Policy net Loss = 1633.69
epoch = 162 epsilon = 0.169 retrain_policy net = 0 Policy net Loss = 1592.99
************************************************************************************************
Normal mode is selected by user Next scene network will be used with frame future f-2,f-1,f0,f+1 
skip_scene_predictor_only_for_benchmarking = 0
************************************************************************************************
Parmeters settings :
next_scene_hid_nodes_L1 = 200
next_scene_hid_nodes_L2 = 200
next_scene_hid_nodes_L3 = 200
policy_net_hid_nodes_L1 = 85
policy_net_hid_nodes_L2 = 25
policy_net_hid_nodes_L3 = 10
next_scene_fc_net.learning_rate = 0.001
next_scene_fc_net.momentum = 0.1
policy_fc_net.learning_rate = 0.001
policy_fc_net.momentum = 0.2
g_replay_size = 200
derating_epsilon = 0.0005
gamma_decay = 0.85
target_policy_on_next_action_selection = 1
target_policy_use_f_p_2_pixel_from_predict_net = 1
target_off_set_to_output_itself = 1
skip_traning_next_scenen = 1
policy_fc_net.use_dropouts =0
policy_fc_net.dropout_proportion = 0
retrain_policy_net = 1
epoch = 163 epsilon = 0.1995 retrain_policy net = 0 Policy net Loss = 1675.75
epoch = 164 epsilon = 0.199 retrain_policy net = 0 Policy net Loss = 1641.67
epoch = 165 epsilon = 0.1985 retrain_policy net = 0 Policy net Loss = 1556.17
epoch = 166 epsilon = 0.198 retrain_policy net = 0 Policy net Loss = 1661.08
epoch = 167 epsilon = 0.1975 retrain_policy net = 0 Policy net Loss = 1483.8
epoch = 168 epsilon = 0.197 retrain_policy net = 0 Policy net Loss = 1627.98
epoch = 169 epsilon = 0.1965 retrain_policy net = 0 Policy net Loss = 1599.01
epoch = 170 epsilon = 0.196 retrain_policy net = 0 Policy net Loss = 1618.56
epoch = 171 epsilon = 0.1955 retrain_policy net = 0 Policy net Loss = 1568.9
epoch = 172 epsilon = 0.195 retrain_policy net = 0 Policy net Loss = 1500.97
epoch = 173 epsilon = 0.1945 retrain_policy net = 0 Policy net Loss = 1526.37
epoch = 174 epsilon = 0.194 retrain_policy net = 0 Policy net Loss = 1600.47
epoch = 175 epsilon = 0.1935 retrain_policy net = 0 Policy net Loss = 1542.1
epoch = 176 epsilon = 0.193 retrain_policy net = 0 Policy net Loss = 1588.66
epoch = 177 epsilon = 0.1925 retrain_policy net = 0 Policy net Loss = 1575.86
epoch = 178 epsilon = 0.192 retrain_policy net = 0 Policy net Loss = 1724.55
epoch = 179 epsilon = 0.1915 retrain_policy net = 0 Policy net Loss = 1370.17
epoch = 180 epsilon = 0.191 retrain_policy net = 0 Policy net Loss = 1394.27
epoch = 181 epsilon = 0.1905 retrain_policy net = 0 Policy net Loss = 1493.27
epoch = 182 epsilon = 0.19 retrain_policy net = 0 Policy net Loss = 1481.21
epoch = 183 epsilon = 0.1895 retrain_policy net = 0 Policy net Loss = 1447.87
epoch = 184 epsilon = 0.189 retrain_policy net = 0 Policy net Loss = 1531.57
epoch = 185 epsilon = 0.1885 retrain_policy net = 0 Policy net Loss = 1432.52
